{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stanford Encyclopedia of Philosophy - Diversity Analysis\n",
    "## Data Extraction, Preprocessing and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by loading the libraries required for this analysis, as well as the function we defined in an external python file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import unidecode\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from sep_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Scraping the *Stanford Encyclopedia of Philosophy* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by scraping all the URLs to articles on the Stanford Encyclopedia of Philosophy (SEP) from its \"contents\" page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1742\n"
     ]
    }
   ],
   "source": [
    "# Url with overview of all the entries\n",
    "url = \"https://plato.stanford.edu/contents.html\"\n",
    "\n",
    "# Load html content, get page text, parse HTML\n",
    "r = requests.get(url)\n",
    "page = r.text\n",
    "soup = BeautifulSoup(page, 'html.parser')\n",
    "\n",
    "# Find <a href> elements which begin with \"plato.stanford.edu/entries\"\n",
    "links = soup.findAll('a')\n",
    "entries = []\n",
    "for link in links:\n",
    "    try:\n",
    "        link_text = link.get(\"href\")\n",
    "        # If the link text is an entry, and it hasn't been added to the list before\n",
    "        if \"entries/\" in link_text  and link_text not in entries:\n",
    "            entries.append(link_text) \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "print(len(entries))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we extract all the references from each of the 1740 articles on the SEP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting from entry #1: entries/abduction/\n",
      "Appending 111 references\n",
      "Extracting from entry #2: entries/abelard/\n",
      "Appending 89 references\n",
      "Extracting from entry #3: entries/abhidharma/\n",
      "Appending 67 references\n",
      "Extracting from entry #4: entries/abilities/\n",
      "Appending 77 references\n",
      "Extracting from entry #5: entries/abner-burgos/\n",
      "Appending 43 references\n"
     ]
    }
   ],
   "source": [
    "# Initialize list of bib elements\n",
    "bib_elements = []\n",
    "\n",
    "# Initialize a count for the entries\n",
    "num_entry = 1\n",
    "\n",
    "# Iterate through the entries and extract all bib elements\n",
    "for entry in entries:\n",
    "    print(f\"Extracting from entry #{num_entry}: {entry}\")\n",
    "    num_entry +=1\n",
    "    url = f\"https://plato.stanford.edu/{entry}\"\n",
    "    li_elements = get_bib_elements(url)\n",
    "    print(f\"Appending {len(li_elements)} references\")\n",
    "    for li_element in li_elements:\n",
    "        bib_elements.append(li_element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will save the extracted references to a .txt file, so we can return to the raw data if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the raw reference data to txt file\n",
    "textfile = open(\"data/bib_items_complete.txt\", \"w\")\n",
    "for element in bib_elements:\n",
    "    textfile.write(str(element) + \"\\n\")\n",
    "textfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Turning the raw text into structured data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will focus on turning the raw references into structured tabular data. To this end, we first load the previously saved .txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data with the raw references\n",
    "filepath = \"data/bib_items_complete.txt\"\n",
    "\n",
    "# Import references from raw text file\n",
    "file = open(filepath, \"r\")\n",
    "content = file.read()\n",
    "\n",
    "# Split the content where a li element ends and a new line starts\n",
    "references = content.split(\"</li>\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each line (and hence reference) in the .txt file, we try to extract the publication year, the name of the authors, and the title of the publication. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2001, The Book of Evidence, ['P. Achinstein']\n",
      "1994, Testimony, Trust, Knowing, ['J. Adler']\n",
      "1979, Linguistic Communication and Speech Acts, ['K. Bach', ' R.  Harnish']\n",
      "1998, Philosophy of Science, ['A. Bird']\n",
      "2010, Quine, Mereology, and Inference to the Best Explanation, ['J. Bigelow']\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to store publication years, author lists, and titles in, as well as different counts\n",
    "years, authors, titles = [], [], []\n",
    "yearless = 0\n",
    "count = 0\n",
    "fail_count = 0\n",
    "\n",
    "# Iterate through references\n",
    "for reference in references:\n",
    "    \n",
    "    try:\n",
    "        # Get publication year\n",
    "        year = extract_year(reference)\n",
    "        # Skip if there is no publication year in the reference\n",
    "        if not year:\n",
    "            yearless+=1\n",
    "            continue\n",
    "        \n",
    "        # Get publication name\n",
    "        title  = extract_title(reference)\n",
    "         \n",
    "        # Check if the author name is \"–––\", indicating its the same as in the previous ref\n",
    "        if \"–––\" in reference:\n",
    "            # Assign the author from the previous reference\n",
    "            names = authors[-1]\n",
    "        else:\n",
    "            # Get author name from the reference\n",
    "            names = extract_authors(reference, year)\n",
    "        \n",
    "        # Append all\n",
    "        years.append(year)\n",
    "        titles.append(title)\n",
    "        authors.append(names)\n",
    "        \n",
    "        # Increment the counter\n",
    "        count+=1\n",
    "        \n",
    "    except:\n",
    "        print(f\"This is number {count}:\")\n",
    "        print(\"General Failure\")\n",
    "        print(reference)\n",
    "        fail_count+=1\n",
    "        \n",
    "# Make sure the list of authors and the list of years is equally long\n",
    "assert len(authors)==len(years) and len(titles)==len(years)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After extracting the publication year, the authors of the publication, and the publication title, we save the structured, tabular data to a .csv file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn into pandas dataframe\n",
    "df = pd.DataFrame({'Authors' : authors,\n",
    "                   'Year' : years,\n",
    "                   'Title' : titles }, \n",
    "                  columns=['Authors','Year', 'Title'])\n",
    "\n",
    "# Write to csv\n",
    "df.to_csv(\"data/sep_reference_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Preprocessing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we begin by loading the data as saved in the previous section, where we have extracted 180 403 references. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data set with 180400 rows.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Authors</th>\n",
       "      <th>Year</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P. Achinstein</td>\n",
       "      <td>2001</td>\n",
       "      <td>The Book of Evidence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>J. Adler</td>\n",
       "      <td>1994</td>\n",
       "      <td>Testimony, Trust, Knowing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K. Bach,  R.  Harnish</td>\n",
       "      <td>1979</td>\n",
       "      <td>Linguistic Communication and Speech Acts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A. Bird</td>\n",
       "      <td>1998</td>\n",
       "      <td>Philosophy of Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>J. Bigelow</td>\n",
       "      <td>2010</td>\n",
       "      <td>Quine, Mereology, and Inference to the Best Ex...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Authors  Year  \\\n",
       "0          P. Achinstein  2001   \n",
       "1               J. Adler  1994   \n",
       "2  K. Bach,  R.  Harnish  1979   \n",
       "3                A. Bird  1998   \n",
       "4             J. Bigelow  2010   \n",
       "\n",
       "                                               Title  \n",
       "0                               The Book of Evidence  \n",
       "1                          Testimony, Trust, Knowing  \n",
       "2           Linguistic Communication and Speech Acts  \n",
       "3                              Philosophy of Science  \n",
       "4  Quine, Mereology, and Inference to the Best Ex...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(\"data/sep_reference_data.csv\")[[\"Authors\", \"Year\", \"Title\"]]\n",
    "\n",
    "# Save initial number of columns\n",
    "initial_len = len(df)\n",
    "\n",
    "# Reformat Authors column\n",
    "df[\"Authors\"] = df[\"Authors\"].apply(lambda x: x[2:-2].replace(\"'\",\"\"))\n",
    "print(f\"Data set with {initial_len} rows.\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by checking how many entries are invalid, i.e. don't have a title, year, or author names. Those rows we will drop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dropped rows: 8973. This is ~5.0% of the original data set.\n"
     ]
    }
   ],
   "source": [
    "# Drop rows without author name\n",
    "df = df[df[\"Authors\"]!=\"(No names)\"]\n",
    "\n",
    "# Drop rows without title\n",
    "df[df[\"Title\"]==\"(Couldn't determine title)\"]\n",
    "print(f\"Number of dropped rows: {initial_len-len(df)}. This is ~{round((initial_len-len(df))/initial_len,3)*100}% of the original data set.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will create a new column for the first author of a publication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Authors</th>\n",
       "      <th>Year</th>\n",
       "      <th>Title</th>\n",
       "      <th>First author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P. Achinstein</td>\n",
       "      <td>2001</td>\n",
       "      <td>The Book of Evidence</td>\n",
       "      <td>P. Achinstein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>J. Adler</td>\n",
       "      <td>1994</td>\n",
       "      <td>Testimony, Trust, Knowing</td>\n",
       "      <td>J. Adler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K. Bach,  R.  Harnish</td>\n",
       "      <td>1979</td>\n",
       "      <td>Linguistic Communication and Speech Acts</td>\n",
       "      <td>K. Bach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A. Bird</td>\n",
       "      <td>1998</td>\n",
       "      <td>Philosophy of Science</td>\n",
       "      <td>A. Bird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>J. Bigelow</td>\n",
       "      <td>2010</td>\n",
       "      <td>Quine, Mereology, and Inference to the Best Ex...</td>\n",
       "      <td>J. Bigelow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Authors  Year  \\\n",
       "0          P. Achinstein  2001   \n",
       "1               J. Adler  1994   \n",
       "2  K. Bach,  R.  Harnish  1979   \n",
       "3                A. Bird  1998   \n",
       "4             J. Bigelow  2010   \n",
       "\n",
       "                                               Title   First author  \n",
       "0                               The Book of Evidence  P. Achinstein  \n",
       "1                          Testimony, Trust, Knowing       J. Adler  \n",
       "2           Linguistic Communication and Speech Acts        K. Bach  \n",
       "3                              Philosophy of Science        A. Bird  \n",
       "4  Quine, Mereology, and Inference to the Best Ex...     J. Bigelow  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get first author\n",
    "df[\"First author\"] = df[\"Authors\"].apply(lambda x: x.split(\",\")[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now checking whether there are columns where the First author name is suspiciously long (over 35 characters) to analyze those. It will presumably be reasonable to drop them, as they will most likely indicate that something went wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6 overly long first author entries.\n"
     ]
    }
   ],
   "source": [
    "# Mark all where first author name is longer than 35 characters\n",
    "df[\"Overlong\"] = df[\"First author\"].apply(lambda x: len(x)>35)\n",
    "\n",
    "# How many are we dealing with?\n",
    "print(f\"There are {len(df[df['Overlong']])} overly long first author entries.\")\n",
    "\n",
    "# Print the top ones\n",
    "df[df[\"Overlong\"]].head()\n",
    "\n",
    "# Drop them\n",
    "df = df[df[\"Overlong\"]==False][[\"Authors\",\"Year\",\"Title\",\"First author\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we want to focus only on publications after 1900, we drop all data points with earlier publication year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Authors</th>\n",
       "      <th>Year</th>\n",
       "      <th>Title</th>\n",
       "      <th>First author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>David Hume</td>\n",
       "      <td>1748</td>\n",
       "      <td>An Enquiry Concerning Human Understanding</td>\n",
       "      <td>David Hume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>Thomas Reid</td>\n",
       "      <td>1788</td>\n",
       "      <td>Essays on the Active Powers of Man</td>\n",
       "      <td>Thomas Reid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>Bernhard Zimmels</td>\n",
       "      <td>1886</td>\n",
       "      <td>Leo Hebraeus: Ein Judischer Philosoph der Rena...</td>\n",
       "      <td>Bernhard Zimmels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>Bernhard Zimmels</td>\n",
       "      <td>1892</td>\n",
       "      <td>Leone Hebreo, Neue Studien</td>\n",
       "      <td>Bernhard Zimmels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>Bernard Bolzano</td>\n",
       "      <td>1837</td>\n",
       "      <td>Wissenschaftslehre</td>\n",
       "      <td>Bernard Bolzano</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Authors  Year  \\\n",
       "261        David Hume  1748   \n",
       "288       Thomas Reid  1788   \n",
       "394  Bernhard Zimmels  1886   \n",
       "395  Bernhard Zimmels  1892   \n",
       "416   Bernard Bolzano  1837   \n",
       "\n",
       "                                                 Title      First author  \n",
       "261          An Enquiry Concerning Human Understanding        David Hume  \n",
       "288                 Essays on the Active Powers of Man       Thomas Reid  \n",
       "394  Leo Hebraeus: Ein Judischer Philosoph der Rena...  Bernhard Zimmels  \n",
       "395                         Leone Hebreo, Neue Studien  Bernhard Zimmels  \n",
       "416                                 Wissenschaftslehre   Bernard Bolzano  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"Year\"]<\"1900\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166433"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df[\"Year\"]>=\"1900\"]\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should be a reasonable pre-processed and filtered data set. It contains 166 437 entries. We will now move to the feature engineering part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Obtain full author names\n",
    "\n",
    "As a majority of references do not contain the full first names of authors (but only initials), we now need to turn to the problem of obtaining full author names. Let us first get an idea how many unique first author entries we have, to then see how many of those contain the full first names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 55968 unique 'Authors' entries\n"
     ]
    }
   ],
   "source": [
    "# Number of different first authors (55.9k)\n",
    "print(f\"There are {len(df['First author'].unique())} unique 'Authors' entries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Match different versions of names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick look at the author names reveals that there are often different versions of the same name in the data set (e.g. \"Richard Boyd\", \"Richard N. Boyd\"). The first step will be to remove middle names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49774"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split authors into list divided by whitespaces, then only retain first and last\n",
    "df[\"First author\"] = df[\"First author\"].apply(lambda x: x.split(\" \")[0]+\" \"+x.split(\" \")[-1])\n",
    "# Check how many unique names we have now\n",
    "len(df[\"First author\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we're removing punctuation to unify abbreviated names (e.g. \"L Bovens\", \"L. Bovens\"). This reduces the number of unique author entries by roughly 700 entries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49034"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"First author\"] = df[\"First author\"].apply(lambda x: x.replace(\".\",\"\"))\n",
    "# Check how many unique names we have now\n",
    "len(df[\"First author\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, we're replacing letters with accent (e.g. \"A. Hajék\"). This reduces the number if unique author entries by roughly another 300 entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48774"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace each name by its closest ASCII representation\n",
    "df[\"First author\"] = df[\"First author\"].apply(lambda x: unidecode.unidecode(x))\n",
    "# Check how many unique names we have now\n",
    "len(df[\"First author\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Find the full name in list and match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we will do is to try to find the full name of entries where only an authors first name initial is available within the data set. To this end, we split the unique first author entries into two lists: one with entries with full first names, and one with entries with abbreviated first names.\n",
    "\n",
    "We can then try to match abbreviated names to full names. We only do so if there is a unique match for the abbreviated name (e.g. \"N Cartwright\", \"Nancy Cartwright\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full names: 26230, Abbreviated names: 22544\n",
      "We found matches for a total of 10893 abbreviated names, of which 9035 are unique.\n"
     ]
    }
   ],
   "source": [
    "# Get the list of unique \"First author\" entries\n",
    "unique_names = df['First author'].unique()\n",
    "\n",
    "# Split the unique author names into abbreviated names (e.g. L Bovens) and full names (e.g. Luc Bovens)\n",
    "full_names, abr_names = sort_names(unique_names)\n",
    "print(f\"Full names: {len(full_names)}, Abbreviated names: {len(abr_names)}\")  \n",
    "\n",
    "# Match abbreviated names to corresponding full names\n",
    "matches = get_matches(full_names, abr_names)\n",
    "\n",
    "# Find unique matches among all matches\n",
    "unique_matches = [match for match in matches if len(match[1])==1]\n",
    "print(f\"We found matches for a total of {len(matches)} abbreviated names, of which {len(unique_matches)} are unique.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to replace all the abbreviated names in our data set that have unique matching full names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Authors</th>\n",
       "      <th>Year</th>\n",
       "      <th>Title</th>\n",
       "      <th>First author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P. Achinstein</td>\n",
       "      <td>2001</td>\n",
       "      <td>The Book of Evidence</td>\n",
       "      <td>Peter Achinstein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>J. Adler</td>\n",
       "      <td>1994</td>\n",
       "      <td>Testimony, Trust, Knowing</td>\n",
       "      <td>J Adler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K. Bach,  R.  Harnish</td>\n",
       "      <td>1979</td>\n",
       "      <td>Linguistic Communication and Speech Acts</td>\n",
       "      <td>Kent Bach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A. Bird</td>\n",
       "      <td>1998</td>\n",
       "      <td>Philosophy of Science</td>\n",
       "      <td>Alexander Bird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>J. Bigelow</td>\n",
       "      <td>2010</td>\n",
       "      <td>Quine, Mereology, and Inference to the Best Ex...</td>\n",
       "      <td>J Bigelow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Authors  Year  \\\n",
       "0          P. Achinstein  2001   \n",
       "1               J. Adler  1994   \n",
       "2  K. Bach,  R.  Harnish  1979   \n",
       "3                A. Bird  1998   \n",
       "4             J. Bigelow  2010   \n",
       "\n",
       "                                               Title      First author  \n",
       "0                               The Book of Evidence  Peter Achinstein  \n",
       "1                          Testimony, Trust, Knowing           J Adler  \n",
       "2           Linguistic Communication and Speech Acts         Kent Bach  \n",
       "3                              Philosophy of Science    Alexander Bird  \n",
       "4  Quine, Mereology, and Inference to the Best Ex...         J Bigelow  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function which takes as input an abbreviated name and returns a full name if a unique match is available\n",
    "# and the initial name otherwise\n",
    "\n",
    "df[\"First author\"] = df[\"First author\"].apply(lambda x: get_full_name(x, unique_matches))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Retrieving full first names from an external website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works so far - have to save to CSV in steps of 1000s and start from where the list left off to be able to do this in chunks. (WORK IN PROGRESS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are still 33613 abbreviated names.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(33613, 5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the names we still need to find\n",
    "df_temp = df[[\"Authors\", \"Year\", \"Title\",\"First author\", \"Abr\"]]\n",
    "\n",
    "# Column of Boolean values to flag which names are abbreviated\n",
    "df_temp[\"Abr\"] = df_temp[\"First author\"].apply(lambda x: x.split(\" \")[0].isupper())\n",
    "\n",
    "# Retrict to abbreviated names\n",
    "df_temp = df_temp[df_temp[\"Abr\"]].copy().reset_index(drop=True)\n",
    "\n",
    "# Print length\n",
    "print(f\"There are still {len(df_temp)} abbreviated names.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define headers for URL request\n",
    "headers = {\n",
    "    'Access-Control-Allow-Origin': '*',\n",
    "    'Access-Control-Allow-Methods': 'GET',\n",
    "    'Access-Control-Allow-Headers': 'Content-Type',\n",
    "    'Access-Control-Max-Age': '3600',\n",
    "    'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:52.0) Gecko/20100101 Firefox/52.0'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33612\n",
      "33612\n",
      "Authors                                         S. Yablo\n",
      "Year                                                1993\n",
      "Title           Philosophy and Phenomenological Research\n",
      "First author                                     S Yablo\n",
      "Abr                                                 True\n",
      "Name: 33612, dtype: object\n",
      "https://philpapers.org/s/S%20Yablo%20Philosophy%20and%20Phenomenological%20Research\n",
      "Error: Alonzo Church\n",
      "Abr name: S Yablo, full name: Alonzo Church, length: True, initials: False, last name: False\n",
      "(33614, 5)\n",
      "33613\n",
      "Authors                                         S. Yablo\n",
      "Year                                                1999\n",
      "Title           Philosophy and Phenomenological Research\n",
      "First author                                     S Yablo\n",
      "Abr                                                 True\n",
      "Name: 33613, dtype: object\n",
      "https://philpapers.org/s/S%20Yablo%20Philosophy%20and%20Phenomenological%20Research\n",
      "Error: Alonzo Church\n",
      "Abr name: S Yablo, full name: Alonzo Church, length: True, initials: False, last name: False\n",
      "(33614, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-37-d39382acc652>:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_temp[\"First author\"][index] = \"(Error)\"\n",
      "<ipython-input-37-d39382acc652>:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_temp[\"Abr\"][index] = False\n"
     ]
    }
   ],
   "source": [
    "# Initialize count\n",
    "count = 0\n",
    "\n",
    "# Find index of first abbreviated name and add count to it (THIS IS WRONG - WE NEED POSITION, NOT)\n",
    "first_abr = df_temp[df_temp[\"Abr\"]].index[0]\n",
    "print(first_abr)\n",
    "\n",
    "# Loop through\n",
    "for count in range(2):\n",
    "    \n",
    "    # Get index by adding count to the determined index of the first abr name \n",
    "    index = first_abr+count\n",
    "    # Get row from data frame\n",
    "    row = df_temp.iloc[index,:]\n",
    "    # Retrieve author\n",
    "    author = row[\"First author\"]\n",
    "    # Retrieve title and remove HTML tags\n",
    "    title = BeautifulSoup(row[\"Title\"],\"lxml\").text\n",
    "    query = f\"{author} {title}\".replace(\" \",\"%20\")\n",
    "    path = \"https://philpapers.org/s/\"+query\n",
    "    \n",
    "    try:\n",
    "        req = requests.get(path, headers)\n",
    "        soup = BeautifulSoup(req.content, 'html.parser')\n",
    "        entry = soup.find_all(\"li\", class_=\"entry\")[0]\n",
    "    \n",
    "        # Loop through all names on the site\n",
    "        for entry in entry.findChildren(\"span\" ,class_=\"name\"):\n",
    "            name = entry.getText()\n",
    "            # Set up checks whether name not too long, whether it matches with initials and last name\n",
    "            length_check = len(name)<50\n",
    "            first_initial_check = name.split(\" \")[0][0]==author.split(\" \")[0][0]\n",
    "            lastname_check = name.split(\" \")[-1]==author.split(\" \")[-1]\n",
    "            # Run checks\n",
    "            if length_check and first_initial_check and lastname_check:\n",
    "                # Add name to the author column\n",
    "                df_temp[\"First author\"][index] = name\n",
    "                # Change the Boolean flag to false\n",
    "                df_temp[\"Abr\"][index] = False\n",
    "                # Break loop as soon as a match is found\n",
    "                print(f\"Success: {name}\")\n",
    "                break\n",
    "    except:\n",
    "        print(f\"BeautifulSoup error with: {author}, {title}\")\n",
    "    # If still no name is found, declare error\n",
    "    if df_temp[\"Abr\"][index]==True:\n",
    "        print(f\"Error: {name}\")\n",
    "        # Declare error\n",
    "        df_temp[\"First author\"][index] = \"(Error)\"\n",
    "        # Change the Boolean flag to false\n",
    "        df_temp[\"Abr\"][index] = False\n",
    "\n",
    "df_temp.head(15)\n",
    "\n",
    "assert df_temp.shape == (33614, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14942"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many unsuccessful attempts to retrieve?\n",
    "len(df_temp[df_temp[\"First author\"]!=\"(Error)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We were able to retrieve 14942 full names. Now we will match the obtained data with the existing data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Postprocess: deunicode, remove middle name, remove punctuation\n",
    "# Find closest ASCII representation\n",
    "df_temp[\"First author\"] = df_temp[\"First author\"].apply(lambda x: unidecode.unidecode(x))\n",
    "# Remove punctuation\n",
    "df_temp[\"First author\"] = df_temp[\"First author\"].apply(lambda x: x.replace(\".\",\"\").replace(\";\",\"\").replace(\",\",\"\"))\n",
    "# Remove middle name\n",
    "df_temp[\"First author\"] = df_temp[\"First author\"].apply(lambda x: x.split(\" \")[0]+\" \"+x.split(\" \")[-1] if x!=\"(Error)\" else x)\n",
    "# Drop duplicate entries\n",
    "df_temp = df_temp.drop_duplicates()\n",
    "\n",
    "df_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two data sets \n",
    "df_updated = pd.merge(\n",
    "    df,\n",
    "    df_temp,\n",
    "    how=\"left\",\n",
    "    on=[\"Authors\",\"Year\",\"Title\"],\n",
    "    left_on=None,\n",
    "    right_on=None,\n",
    "    left_index=False,\n",
    "    right_index=False,\n",
    "    sort=False,\n",
    "    suffixes=(\"_x\", \"_y\"),\n",
    "    copy=True,\n",
    "    indicator=False,\n",
    "    validate=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>First author</th>\n",
       "      <th>Year</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Peter Achinstein</td>\n",
       "      <td>2001</td>\n",
       "      <td>The Book of Evidence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jonathan Adler</td>\n",
       "      <td>1994</td>\n",
       "      <td>Testimony, Trust, Knowing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kent Bach</td>\n",
       "      <td>1979</td>\n",
       "      <td>Linguistic Communication and Speech Acts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alexander Bird</td>\n",
       "      <td>1998</td>\n",
       "      <td>Philosophy of Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>John Bigelow</td>\n",
       "      <td>2010</td>\n",
       "      <td>Quine, Mereology, and Inference to the Best Ex...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       First author  Year                                              Title\n",
       "0  Peter Achinstein  2001                               The Book of Evidence\n",
       "1    Jonathan Adler  1994                          Testimony, Trust, Knowing\n",
       "2         Kent Bach  1979           Linguistic Communication and Speech Acts\n",
       "3    Alexander Bird  1998                              Philosophy of Science\n",
       "4      John Bigelow  2010  Quine, Mereology, and Inference to the Best Ex..."
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if first author_y NaN or author_y \"(Error)\": first author = first author_x; else first author = first_author_y\n",
    "df_updated[\"First author\"] = df_updated.apply(lambda x: x[\"First author_x\"] if (str(x[\"First author_y\"])==\"nan\" or x[\"First author_y\"]==\"(Error)\") else x[\"First author_y\"], axis = 1)\n",
    "df_updated = df_updated[[\"First author\",\"Year\", \"Title\"]]\n",
    "df_updated.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>First author</th>\n",
       "      <th>Year</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Peter Achinstein</td>\n",
       "      <td>2001</td>\n",
       "      <td>The Book of Evidence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jonathan Adler</td>\n",
       "      <td>1994</td>\n",
       "      <td>Testimony, Trust, Knowing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kent Bach</td>\n",
       "      <td>1979</td>\n",
       "      <td>Linguistic Communication and Speech Acts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alexander Bird</td>\n",
       "      <td>1998</td>\n",
       "      <td>Philosophy of Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>John Bigelow</td>\n",
       "      <td>2010</td>\n",
       "      <td>Quine, Mereology, and Inference to the Best Ex...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       First author  Year                                              Title\n",
       "0  Peter Achinstein  2001                               The Book of Evidence\n",
       "1    Jonathan Adler  1994                          Testimony, Trust, Knowing\n",
       "2         Kent Bach  1979           Linguistic Communication and Speech Acts\n",
       "3    Alexander Bird  1998                              Philosophy of Science\n",
       "4      John Bigelow  2010  Quine, Mereology, and Inference to the Best Ex..."
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the list of unique \"First author\" entries\n",
    "unique_names = df_updated['First author'].unique()\n",
    "\n",
    "# Split the unique author names into abbreviated names (e.g. L Bovens) and full names (e.g. Luc Bovens)\n",
    "full_names, abr_names = sort_names(unique_names)\n",
    "print(f\"Full names: {len(full_names)}, Abbreviated names: {len(abr_names)}\")  \n",
    "\n",
    "# Match abbreviated names to corresponding full names\n",
    "matches = get_matches(full_names, abr_names)\n",
    "\n",
    "# Find unique matches among all matches\n",
    "unique_matches = [match for match in matches if len(match[1])==1]\n",
    "print(f\"We found matches for a total of {len(matches)} abbreviated names, of which {len(unique_matches)} are unique.\")\n",
    "\n",
    "# Replace abbreviated author names with full author names\n",
    "df_updated[\"First author\"] = df_updated[\"First author\"].apply(lambda x: get_full_name(x, unique_matches))\n",
    "df_updated.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will conduct a final test to see how many entries have full names, and how many have abbreviated names. We'll drop the abbreviated names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of entries to keep: 146472. Number of entries to drop: 0 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "df_updated[\"Abr\"] = df_updated[\"First author\"].apply(lambda x: x.split(\" \")[0].isupper())\n",
    "keep_count = len(df_updated[~df_updated[\"Abr\"]])\n",
    "drop_count = len(df_updated[df_updated[\"Abr\"]])\n",
    "print(f\" Number of entries to keep: {keep_count}. Number of entries to drop: {drop_count} ({round(drop_count/(keep_count+drop_count),2)*100}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means we have to drop another 19988 or 12% of entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146472, 3)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_updated = df_updated[~df_updated[\"Abr\"]][[\"First author\",\"Year\",\"Title\"]]\n",
    "df_updated.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will be the data set we will use for our analysis. Of the initial ~180 000 raw entries we were able to extract valid information (including finding the full first name) for more than 145 000. This is over 80% of the initial, raw data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data set to CSV\n",
    "df_updated.to_csv(\"data/dataset_full_names.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Retrieving information on affiliation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>First author</th>\n",
       "      <th>Year</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Peter Achinstein</td>\n",
       "      <td>2001</td>\n",
       "      <td>The Book of Evidence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jonathan Adler</td>\n",
       "      <td>1994</td>\n",
       "      <td>Testimony, Trust, Knowing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kent Bach</td>\n",
       "      <td>1979</td>\n",
       "      <td>Linguistic Communication and Speech Acts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alexander Bird</td>\n",
       "      <td>1998</td>\n",
       "      <td>Philosophy of Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>John Bigelow</td>\n",
       "      <td>2010</td>\n",
       "      <td>Quine, Mereology, and Inference to the Best Ex...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       First author  Year                                              Title\n",
       "0  Peter Achinstein  2001                               The Book of Evidence\n",
       "1    Jonathan Adler  1994                          Testimony, Trust, Knowing\n",
       "2         Kent Bach  1979           Linguistic Communication and Speech Acts\n",
       "3    Alexander Bird  1998                              Philosophy of Science\n",
       "4      John Bigelow  2010  Quine, Mereology, and Inference to the Best Ex..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/dataset_full_names.csv\")[[\"First author\",\"Year\",\"Title\"]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of unique names (29k)\n",
    "unique_names = df[\"First author\"].unique()\n",
    "\n",
    "# set URL\n",
    "url = \"https://philpeople.org/find-philosopher/search?utf8=%E2%9C%93&button=&keywords=\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty data frame and save to csv \n",
    "#df_aff = pd.DataFrame(columns=[\"Name\",\"Affiliation\"])\n",
    "#df_aff.to_csv(\"data/affiliations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_aff = pd.read_csv(\"data/affiliations.csv\")[[\"Name\",\"Affiliation\"]]\n",
    "\n",
    "index = len(df_aff)\n",
    "interval = 5_000\n",
    "\n",
    "# Create empty list\n",
    "affiliations_list = []\n",
    "\n",
    "for name in unique_names[index:]:\n",
    "    # Define philosopher-specific query\n",
    "    path = url+name.replace(\" \",\"+\")\n",
    "    \n",
    "    try:\n",
    "        req = requests.get(path, headers)\n",
    "        soup = BeautifulSoup(req.content, 'html.parser')\n",
    "    \n",
    "        profile_name_tags = soup.find_all(\"div\", class_=\"profile-name\")\n",
    "        print(f\"Name: {name}\")\n",
    "        print(f\"Number of profile names: {len(profile_name_tags)}\")\n",
    "        # If there's no profile, append \"None and skip to next\"\n",
    "        if len(profile_name_tags)==0:\n",
    "            affiliations_list.append([name, \"None\"])\n",
    "            continue   \n",
    "        \n",
    "        for profile_name_tag in profile_name_tags:\n",
    "            # Extract name on website in ASCII\n",
    "            profile_name = unidecode.unidecode(profile_name_tag.get('title','No title attribue'))\n",
    "            print(profile_name)\n",
    "        \n",
    "            # Check whether first and last name match\n",
    "            cond_first_name = profile_name.split(\" \")[0]==name.split(\" \")[0]\n",
    "            cond_last_name = profile_name.split(\" \")[-1]==name.split(\" \")[-1]\n",
    "            if cond_first_name and cond_last_name:\n",
    "                # Get the affiliation\n",
    "                affiliation_tag = profile_name_tag.find_next(\"span\", class_=\"affil\")\n",
    "                affiliation = affiliation_tag.get('title','None')\n",
    "                affiliations_list.append([name, affiliation])\n",
    "                print(f\"Result: {name}, Affiliation: {affiliation}\")\n",
    "                break\n",
    "                \n",
    "    except:\n",
    "        affiliations_list.append([name, \"None\"])\n",
    "\n",
    "# Create temporary data frame with new entries        \n",
    "df_aff_temp = pd.DataFrame(affiliations_list, columns=[\"Name\",\"Affiliation\"])\n",
    "\n",
    "# Concatenate to existing entries\n",
    "df_aff = pd.concat([df_aff,df_aff_temp])\n",
    "\n",
    "# Save to CSV\n",
    "# df_aff.to_csv(\"data/affiliations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aff = df_aff.rename(columns={\"Name\":\"First author\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_counts = df.groupby(\"First author\").count().reset_index()\n",
    "\n",
    "df_full = pd.merge(\n",
    "    df_counts,\n",
    "    df_aff,\n",
    "    how=\"left\",\n",
    "    on=[\"First author\"],\n",
    "    left_on=None,\n",
    "    right_on=None,\n",
    "    left_index=False,\n",
    "    right_index=False,\n",
    "    sort=False,\n",
    "    suffixes=(\"_x\", \"_y\"),\n",
    "    copy=True,\n",
    "    indicator=False,\n",
    "    validate=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = df_full.rename(columns={\"Year\":\"Count\"})[[\"First author\", \"Count\",\"Affiliation\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Affiliation</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>75459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New York University</td>\n",
       "      <td>1915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rutgers University - New Brunswick</td>\n",
       "      <td>1824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Oxford University</td>\n",
       "      <td>1569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>University of Notre Dame</td>\n",
       "      <td>1485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Affiliation  Count\n",
       "0                                None  75459\n",
       "1                 New York University   1915\n",
       "2  Rutgers University - New Brunswick   1824\n",
       "3                   Oxford University   1569\n",
       "4            University of Notre Dame   1485"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grouped = df_full.groupby(\"Affiliation\").sum().sort_values(\"Count\", ascending=False).reset_index()\n",
    "df_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-120-41565c37b548>:12: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_grouped[\"Affiliation\"] = df_grouped[\"Affiliation\"].str.replace(k,v).str.strip()\n"
     ]
    }
   ],
   "source": [
    "# Next step: manually sort out duplicates\n",
    "\n",
    "replace = {\n",
    "    \"\\(PhD\\)\":\"\",\n",
    "    \"\\(DPhil\\)\":\"\",\n",
    "    \"University of Oxford\":\"Oxford University\",\n",
    "    \"University Of Oxford\":\"Oxford University\",\n",
    "    \"UCLA\":\"University of California, Los Angeles\",   \n",
    "}\n",
    "\n",
    "# Iterate through the replacements\n",
    "for k, v in replace.items():\n",
    "    df_grouped[\"Affiliation\"] = df_grouped[\"Affiliation\"].str.replace(k,v).str.strip()\n",
    "\n",
    "# Put back together    \n",
    "df_grouped = df_grouped.groupby(\"Affiliation\").sum().sort_values(\"Count\", ascending=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "df_grouped.to_csv(\"data/university_counts.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
